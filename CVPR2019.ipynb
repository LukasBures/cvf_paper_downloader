{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVPR2019\n",
    "\n",
    "Paper download from Computer Vision Foundation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import socket\n",
    "import time\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url        = 'http://openaccess.thecvf.com/'\n",
    "html_url        = 'CVPR2019.py'\n",
    "pdf_folder_url  = 'content_CVPR2019_2018/papers/'\n",
    "\n",
    "\n",
    "save_html_name = 'cvpr2019.html' \n",
    "conference_name = 'CVPR2019' \n",
    "pdf_local_folder_name = 'cvpr2019/'\n",
    "pdf_workshops_local_folder_name = 'cvpr2019/workshops' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(pdf_local_folder_name):\n",
    "    os.makedirs(pdf_local_folder_name)\n",
    "    \n",
    "if not os.path.exists(pdf_workshops_local_folder_name):\n",
    "    os.makedirs(pdf_workshops_local_folder_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request(base_url + html_url)\n",
    "html = urllib.request.urlopen(req)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "paper_infos = soup.find('dl')\n",
    "paper_titles = paper_infos.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls_to_download = []\n",
    "for curr_title in paper_titles:\n",
    "    str_to_check = str(curr_title.get('href'))\n",
    "    if 'pdf' in str_to_check:\n",
    "        urls_to_download += [base_url + '/' + str_to_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_papers = []\n",
    "\n",
    "for curr_url in tqdm(urls_to_download):\n",
    "\n",
    "    filename = curr_url.split('/')[-1]\n",
    "    save_name = os.path.join(pdf_local_folder_name, filename)\n",
    "\n",
    "    if os.path.exists(save_name):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        http_status_code = urllib.request.urlopen(curr_url).getcode()\n",
    "    except:\n",
    "        print('Error Code ', http_status_code)\n",
    "        failed_papers.append(filename)\n",
    "\n",
    "    if http_status_code is 200: # if remote url exists\n",
    "    \n",
    "        try:\n",
    "            urllib.request.urlretrieve(curr_url, save_name)\n",
    "        except:\n",
    "            print('Timeout')\n",
    "            failed_papers.append(filename)\n",
    "\n",
    "    else: # url not found\n",
    "        print('Error')\n",
    "        failed_papers.append(filename)\n",
    "        \n",
    "#     time.sleep(0.2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download workshop papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request('http://openaccess.thecvf.com/CVPR2019_workshops/menu.py')\n",
    "html = urllib.request.urlopen(req)\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "paper_infos = soup.find('dl')\n",
    "paper_titles = paper_infos.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshops_to_download = []\n",
    "for curr_title in paper_titles:\n",
    "    str_to_check = str(curr_title.get('href'))\n",
    "    if '.py' in str_to_check:\n",
    "        workshops_to_download += ['http://openaccess.thecvf.com/CVPR2019_workshops/' + str_to_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for curr_workshop in tqdm(workshops_to_download[:-1]):\n",
    "    workshop_name = curr_workshop.split('/')[-1][9:-3]\n",
    "    \n",
    "    curr_dir = pdf_workshops_local_folder_name + '/' + workshop_name\n",
    "    \n",
    "    if not os.path.exists(curr_dir):\n",
    "        os.makedirs(curr_dir)\n",
    "    \n",
    "    req = urllib.request.Request(curr_workshop)\n",
    "    html = urllib.request.urlopen(req)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    paper_infos = soup.find('dl')\n",
    "    paper_titles = paper_infos.find_all('a')\n",
    "    \n",
    "    workshop_urls_to_download = []\n",
    "    \n",
    "    for curr_title in paper_titles:\n",
    "        str_to_check = str(curr_title.get('href'))\n",
    "        if 'pdf' in str_to_check:\n",
    "            workshop_urls_to_download += [base_url + '/' + str_to_check[3:]]\n",
    "    \n",
    "    for curr_url in workshop_urls_to_download:\n",
    "        \n",
    "        filename = curr_url.split('/')[-1]\n",
    "        save_name = os.path.join(curr_dir, filename)\n",
    "        \n",
    "        try:\n",
    "            http_status_code = urllib.request.urlopen(curr_url).getcode()\n",
    "        except:\n",
    "            print('Error ', http_status_code, ' --> ', curr_url)\n",
    "\n",
    "\n",
    "        if http_status_code is 200: # if remote url exists\n",
    "\n",
    "            try:\n",
    "                urllib.request.urlretrieve(curr_url, save_name)\n",
    "            except:\n",
    "                print('timeout')\n",
    "\n",
    "        else: # url not found\n",
    "            print('Error')\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
